@article{greenai-cacm20,
author = {Schwartz, Roy and Dodge, Jesse and Smith, Noah A. and Etzioni, Oren},
title = {Green {AI}},
year = {2020},
issue_date = {December 2020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {63},
number = {12},
issn = {0001-0782},
url = {https://doi.org/10.1145/3381831},
doi = {10.1145/3381831},
abstract = {Creating efficiency in AI research will decrease its carbon footprint and increase its inclusivity as deep learning study should not require the deepest pockets.},
journal = {Commun. ACM},
pages = {54â€“63},
numpages = {10}
}

@inproceedings{tvm-osdi18,
  title={{TVM}: An automated end-to-end optimizing compiler for deep learning},
  author={Chen, Tianqi and Moreau, Thierry and Jiang, Ziheng and Zheng, Lianmin and Yan, Eddie and Shen, Haichen and Cowan, Meghan and Wang, Leyuan and Hu, Yuwei and Ceze, Luis and others},
  booktitle={OSDI},
  year={2018}
}

@inproceedings{gandiva-osdi18,
	title        = {Gandiva: Introspective cluster scheduling for deep learning},
	author       = {Xiao, Wencong and Bhardwaj, Romil and Ramjee, Ramachandran and Sivathanu, Muthian and Kwatra, Nipun and Han, Zhenhua and Patel, Pratyush and Peng, Xuan and Zhao, Hanyu and Zhang, Quanlu and others},
	year         = 2018,
	booktitle    = {OSDI}
}

@inproceedings{optimus-eurosys18,
  title={Optimus: an efficient dynamic resource scheduler for deep learning clusters},
  author={Peng, Yanghua and Bao, Yixin and Chen, Yangrui and Wu, Chuan and Guo, Chuanxiong},
  booktitle={EuroSys},
  year={2018}
}

@inproceedings{tiresias-nsdi19,
	title        = {Tiresias: A {GPU} cluster manager for distributed deep learning},
	author       = {Gu, Juncheng and Chowdhury, Mosharaf and Shin, Kang G and Zhu, Yibo and Jeon, Myeongjae and Qian, Junjie and Liu, Hongqiang and Guo, Chuanxiong},
	year         = 2019,
	booktitle    = {NSDI}
}

@inproceedings{monet-iclr20,
  title={Memory Optimization for Deep Networks},
  author={Aashaka Shah and Chao-Yuan Wu and Jayashree Mohan and Vijay Chidambaram and Philipp Kraehenbuehl},
  booktitle={International Conference on Learning Representations},
  year={2021},
  url={https://openreview.net/forum?id=bnY0jm4l59}
}

@misc{nvml,
	title        = {{{NVIDIA Management Library (NVML)}}},
	howpublished = {\url{https://developer.nvidia.com/nvidia-management-library-nvml}}
}

@misc{nvidia-smi,
	title        = {{{NVIDIA System Management Interface}}},
	howpublished = {\url{https://developer.nvidia.com/nvidia-system-management-interface}}
}




@article{deepspeech-arxiv14,
  title={Deep speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014}
}

@inproceedings{imagenet-cvpr09,
  title={{ImageNet}: A large-scale hierarchical image database},
  author={Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Li, Kai and Fei-Fei, Li},
  booktitle={CVPR},
  year={2009}
}

@article{albert-iclr20,
  title={{ALBERT}: A lite {BERT} for self-supervised learning of language representations},
  author={Lan, Zhenzhong and Chen, Mingda and Goodman, Sebastian and Gimpel, Kevin and Sharma, Piyush and Soricut, Radu},
  journal={ICLR},
  year={2020}
}

@article{dlmedical,
  title={Deep learning in medical image analysis},
  author={Shen, Dinggang and Wu, Guorong and Suk, Heung-Il},
  journal={Annual review of biomedical engineering},
  volume={19},
  pages={221--248},
  year={2017},
  publisher={Annual Reviews}
}

@inproceedings{mlaas-nsdi22,
	title={{MLaaS} in the Wild: Workload Analysis and Scheduling in Large-Scale Heterogeneous {GPU} Clusters},
	author={Weng, Qizhen and Xiao, Wencong and Yu, Yinghao and Wang, Wei and Wang, Cheng and He, Jian and Li, Yong and Zhang, Liping and Lin, Wei and Ding, Yu},
	booktitle={NSDI},
	year={2022}
}

@inproceedings{resnet-cvpr16,
	title={Deep residual learning for image recognition},
	author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
	booktitle={CVPR},
	year={2016}
}

@inproceedings{dnn-recommendation-fb-hpca20,
	title={The architectural implications of facebook's {DNN}-based personalized recommendation},
	author={Gupta, Udit and Wu, Carole-Jean and Wang, Xiaodong and Naumov, Maxim and Reagen, Brandon and Brooks, David and Cottel, Bradford and Hazelwood, Kim and Hempstead, Mark and Jia, Bill and others},
	booktitle={HPCA},
	year={2020},
}

@inproceedings{applied-ml-at-fb-hpca18,
	title={Applied machine learning at {Facebook}: A datacenter infrastructure perspective},
	author={Hazelwood, Kim and Bird, Sarah and Brooks, David and Chintala, Soumith and Diril, Utku and Dzhulgakov, Dmytro and Fawzy, Mohamed and Jia, Bill and Jia, Yangqing and Kalro, Aditya and others},
	booktitle={HPCA},
	year={2018},
}

@misc{nvidia-a100,
	title= {{{NVIDIA A100}}},
	howpublished={\url{https://www.nvidia.com/en-us/data-center/a100/}}
}

@article{patterson2021carbon,
	title={Carbon emissions and large neural network training},
	author={Patterson, David and Gonzalez, Joseph and Le, Quoc and Liang, Chen and Munguia, Lluis-Miquel and Rothchild, Daniel and So, David and Texier, Maud and Dean, Jeff},
	journal={arXiv preprint arXiv:2104.10350},
	year={2021}
}

@article{gpu-dvfs-survey,
	title={A survey and measurement study of {GPU} {DVFS}  on energy conservation},
	author={Mei, Xinxin and Wang, Qiang and Chu, Xiaowen},
	journal={Digital Communications and Networks},
	volume={3},
	number={2},
	pages={89--100},
	year={2017},
	publisher={Elsevier}
}


@article{autonomous-driving1,
	title={Safe, multi-agent, reinforcement learning for autonomous driving},
	author={Shalev-Shwartz, Shai and Shammah, Shaked and Shashua, Amnon},
	journal={arXiv preprint arXiv:1610.03295},
	year={2016}
}

@misc{apple-siri,
	title= {{{Siri - Apple}}},
	howpublished={\url{https://www.apple.com/siri/}}
}


@inproceedings{integrated-gpu-power-model-isca10,
	title={An integrated {GPU} power and performance model},
	author={Hong, Sunpyo and Kim, Hyesoon},
	booktitle={ISCA},
	year={2010}
}

@inproceedings{gpu-power-model-analytical,
	title={A performance and energy consumption analytical model for {GPU}},
	author={Luo, Cheng and Suda, Reiji},
	booktitle={2011 IEEE ninth international conference on dependable, autonomic and secure computing},
	year={2011},
}

@article{liang2022metashift,
	title={MetaShift: A Dataset of Datasets for Evaluating Contextual Distribution Shifts and Training Conflicts},
	author={Liang, Weixin and Zou, James},
	journal={arXiv preprint arXiv:2202.06523},
	year={2022}
}

@article{learning-context-drift,
	title={Learning under concept drift: A review},
	author={Lu, Jie and Liu, Anjin and Dong, Fan and Gu, Feng and Gama, Joao and Zhang, Guangquan},
	journal={IEEE Transactions on Knowledge and Data Engineering},
	volume={31},
	number={12},
	pages={2346--2363},
	year={2018},
	publisher={IEEE}
}

@inproceedings{treehouse,
    author    = {Thomas Anderson and Adam Belay and Mosharaf Chowdhury and Asaf Cidon and Irene Zhang},
    booktitle = {HotCarbon},
    title     = {Treehouse: A Case For Carbon-Aware Datacenter Software},
    year      = {2022},
}

@inproceedings{fb-sustainable-ai,
 author = {Wu, Carole-Jean and Raghavendra, Ramya and Gupta, Udit and Acun, Bilge and Ardalani, Newsha and Maeng, Kiwan and Chang, Gloria and Aga, Fiona and Huang, Jinshi and Bai, Charles and Gschwind, Michael and Gupta, Anurag and Ott, Myle and Melnikov, Anastasia and Candido, Salvatore and Brooks, David and Chauhan, Geeta and Lee, Benjamin and Lee, Hsien-Hsin and Akyildiz, Bugra and Balandat, Maximilian and Spisak, Joe and Jain, Ravi and Rabbat, Mike and Hazelwood, Kim},
 booktitle = {Proceedings of Machine Learning and Systems},
 title = {Sustainable {AI}: Environmental Implications, Challenges and Opportunities},
 year = {2022}
}

@inproceedings{measuring-carbon,
  author = {Dodge, Jesse and Prewitt, Taylor and Tachet des Combes, Remi and Odmark, Erika and Schwartz, Roy and Strubell, Emma and Luccioni, Alexandra Sasha and Smith, Noah A. and DeCario, Nicole and Buchanan, Will},
  title = {Measuring the Carbon Intensity of {AI} in Cloud Instances},
  year = {2022},
  booktitle = {ACM Conference on Fairness, Accountability, and Transparency},
}

@article{experiment-impact-tracker,
	title={Towards the systematic reporting of the energy and carbon footprints of machine learning},
	author={Henderson, Peter and Hu, Jieru and Romoff, Joshua and Brunskill, Emma and Jurafsky, Dan and Pineau, Joelle},
	journal={Journal of Machine Learning Research},
	volume={21},
	number={248},
	pages={1--43},
	year={2020}
}

@misc{carbontracker,
  title={Carbontracker: Tracking and Predicting the Carbon Footprint of Training Deep Learning Models},
  author={Lasse F. Wolff Anthony and Benjamin Kanding and Raghavendra Selvan},
  howpublished={ICML Workshop on Challenges in Deploying and monitoring Machine Learning Systems},
  year={2020}
}

@article{dawnbench-tta,
	title={Analysis of dawnbench, a time-to-accuracy machine learning performance benchmark},
	author={Coleman, Cody and Kang, Daniel and Narayanan, Deepak and Nardi, Luigi and Zhao, Tian and Zhang, Jian and Bailis, Peter and Olukotun, Kunle and R{\'e}, Chris and Zaharia, Matei},
	journal={ACM SIGOPS Operating Systems Review},
	year={2019},
}

@inproceedings{benchmark-ai-accelerators,
	title={Benchmarking the performance and energy efficiency of {AI} accelerators for {AI} training},
	author={Wang, Yuxin and Wang, Qiang and Shi, Shaohuai and He, Xin and Tang, Zhenheng and Zhao, Kaiyong and Chu, Xiaowen},
	booktitle={20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)},
	year={2020},
}

@inproceedings{gpu-70percent,
	title={Towards power efficiency in deep learning on data center hardware},
	author={Hodak, Miro and Gorkovenko, Masha and Dholakia, Ajay},
	booktitle={IEEE International Conference on Big Data},
	year={2019},
}

@article{nonstationary-bandit,
	title        = {Stochastic multi-armed-bandit problem with non-stationary rewards},
	author       = {Besbes, Omar and Gur, Yonatan and Zeevi, Assaf},
	year         = 2014,
	journal      = {NeurIPS}
}

@article{pytorch,
	title        = {Pytorch: An imperative style, high-performance deep learning library},
	author       = {Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and others},
	year         = 2019,
	journal      = {NeurIPS}
}

@article{ts-tutorial,
	title={A tutorial on thompson sampling},
	author={Russo, Daniel J and Van Roy, Benjamin and Kazerouni, Abbas and Osband, Ian and Wen, Zheng and others},
	journal={Foundations and Trends{\textregistered} in Machine Learning},
	volume={11},
	number={1},
	pages={1--96},
	year={2018},
	publisher={Now Publishers, Inc.}
}

@article{ts-concurrent,
  title={A modern Bayesian look at the multi-armed bandit},
  author={Scott, Steven L},
  journal={Applied Stochastic Models in Business and Industry},
  volume={26},
  number={6},
  pages={639--658},
  year={2010},
  publisher={Wiley Online Library}
}

@article{conjugate,
  title={A Compendium of Conjugate Priors},
  author={Fink, Daniel},
  year={1997}
}

@inproceedings{narya,
	title        = {Predictive and Adaptive Failure Mitigation to Avert Production Cloud {VM} Interruptions},
	author       = {Levy, Sebastien and Yao, Randolph and Wu, Youjiang and Dang, Yingnong and Huang, Peng and Mu, Zheng and Zhao, Pu and Ramani, Tarun and Govindaraju, Naga and Li, Xukun and others},
	year         = 2020,
	booktitle    = {OSDI}
}

@inproceedings{marcus2021bao,
	title={Bao: Making learned query optimization practical},
	author={Marcus, Ryan and Negi, Parimarjan and Mao, Hongzi and Tatbul, Nesime and Alizadeh, Mohammad and Kraska, Tim},
	booktitle={SIGMOD},
	year={2021}
}

@article{empirical-ts,
	title        = {An empirical evaluation of thompson sampling},
	author       = {Chapelle, Olivier and Li, Lihong},
	year         = 2011,
	journal      = {NeurIPS}
}

@article{ucb1985,
	title={Asymptotically efficient adaptive allocation rules},
	author={Lai, Tze Leung and Robbins, Herbert and others},
	journal={Advances in applied mathematics},
	volume={6},
	number={1},
	pages={4--22},
	year={1985}
}

@article{ucb2002,
	title={Finite-time analysis of the multiarmed bandit problem},
	author={Auer, Peter and Cesa-Bianchi, Nicolo and Fischer, Paul},
	journal={Machine learning},
	volume={47},
	number={2},
	pages={235--256},
	year={2002},
	publisher={Springer}
}

@article{thompson1933likelihood,
	title={On the likelihood that one unknown probability exceeds another in view of the evidence of two samples},
	author={Thompson, William R},
	journal={Biometrika},
	volume={25},
	number={3-4},
	pages={285--294},
	year={1933},
	publisher={Oxford University Press}
}

@inproceedings{ncf,
	title={Neural collaborative filtering},
	author={He, Xiangnan and Liao, Lizi and Zhang, Hanwang and Nie, Liqiang and Hu, Xia and Chua, Tat-Seng},
	booktitle={Proceedings of the 26th international conference on world wide web},
	year={2017}
}

@article{megatron-lm,
  title={Megatron-lm: Training multi-billion parameter language models using model parallelism},
  author={Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and LeGresley, Patrick and Casper, Jared and Catanzaro, Bryan},
  journal={arXiv preprint arXiv:1909.08053},
  year={2019}
}

@inproceedings{deepspeed-billionparam,
	title={Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters},
	author={Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
	booktitle={Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
	pages={3505--3506},
	year={2020}
}

@article{rnn-hardware-survey,
	title={A survey on hardware accelerators and optimization techniques for {RNNs}},
	author={Mittal, Sparsh and Umesh, Sumanth},
	journal={Journal of Systems Architecture},
	volume={112},
	pages={101839},
	year={2021},
	publisher={Elsevier}
}

@article{dnn-hardware-survey,
	title={Hardware and software optimizations for accelerating deep neural networks: Survey of current trends, challenges, and the road ahead},
	author={Capra, Maurizio and Bussolino, Beatrice and Marchisio, Alberto and Masera, Guido and Martina, Maurizio and Shafique, Muhammad},
	journal={IEEE Access},
	volume={8},
	pages={225134--225180},
	year={2020},
	publisher={IEEE}
}

@article{lr-scaling-prescription,
  author  = {Diego Granziol and Stefan Zohren and Stephen Roberts},
  title   = {Learning Rates as a Function of Batch Size: A Random Matrix Theory Approach to Neural Network Training},
  journal = {Journal of Machine Learning Research},
  year    = {2022},
  volume  = {23},
  number  = {173},
  pages   = {1--65},
}

@inproceedings{lr-scaling-sqr,
	title        = {Train longer, generalize better: closing the generalization gap in large batch training of neural networks},
	author       = {Hoffer, Elad and Hubara, Itay and Soudry, Daniel},
	year         = 2017,
	booktitle    = {NeurIPS}
}

@article{lr-scaling-linear,
  title={Accurate, large minibatch sgd: Training imagenet in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@article{electricity-dataset,
  title={Splice-2 comparative evaluation: Electricity pricing},
  author={Harries, Michael and Wales, New South},
  year={1999},
  publisher={Citeseer}
}

@inproceedings{airlines-dataset,
  title={Moa: Massive online analysis, a framework for stream classification and clustering},
  author={Bifet, Albert and Holmes, Geoff and Pfahringer, Bernhard and Kranen, Philipp and Kremer, Hardy and Jansen, Timm and Seidl, Thomas},
  booktitle={Proceedings of the first workshop on applications of pattern analysis},
  year={2010},
}

@inproceedings{circle-dataset,
  title={Learning with drift detection},
  author={Gama, Joao and Medas, Pedro and Castillo, Gladys and Rodrigues, Pedro},
  booktitle={Brazilian symposium on artificial intelligence},
  year={2004},
}

@inproceedings{hyperplane-dataset,
  title={Mining time-changing data streams},
  author={Hulten, Geoff and Spencer, Laurie and Domingos, Pedro},
  booktitle={Proceedings of the seventh ACM international conference on Knowledge discovery and data mining (SIGKDD)},
  year={2001}
}

@inproceedings{matchmaker,
	author = {Mallick, Ankur and Hsieh, Kevin and Arzani, Behnaz and Joshi, Gauri},
	booktitle = {MLSys},
	title = {Matchmaker: Data Drift Mitigation in Machine Learning for Large-Scale Systems},
	year = {2022}}

@article{adadelta,
	title={Adadelta: an adaptive learning rate method},
	author={Zeiler, Matthew D},
	journal={arXiv preprint arXiv:1212.5701},
	year={2012}
}


@misc{cifar-url,
	title        = {{{CIFAR-10 and CIFAR-100 datasets}}},
	howpublished = {\url{https://www.cs.toronto.edu/~kriz/cifar.html}}
}

@article{cifar-paper,
	title={Learning multiple layers of features from tiny images},
	author={Krizhevsky, Alex and Hinton, Geoffrey and others},
	year={2009},
	publisher={Citeseer}
}

@inproceedings{bert,
    title = "{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding",
    author = "Devlin, Jacob  and
      Chang, Ming-Wei  and
      Lee, Kenton  and
      Toutanova, Kristina",
    booktitle = "Proceedings of the 2019 Conference of the North {A}merican Chapter of the Association for Computational Linguistics (NAACL)",
    year = "2019",
}


@inproceedings{gpt3,
 title = {Language Models are Few-Shot Learners},
 author = {Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel and Wu, Jeffrey and Winter, Clemens and Hesse, Chris and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and McCandlish, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario},
 booktitle = {NeurIPS},
 year = {2020}
}

@inproceedings{shufflenetv2,
	title        = {Shufflenet v2: Practical guidelines for efficient {CNN} architecture design},
	author       = {Ma, Ningning and Zhang, Xiangyu and Zheng, Hai-Tao and Sun, Jian},
	year         = 2018,
	booktitle    = {ECCV}
}

@inproceedings{adam,
  author={Diederik P. Kingma and Jimmy Ba},
  title={Adam: A Method for Stochastic Optimization},
  year={2015},
  url={http://arxiv.org/abs/1412.6980},
  booktitle={ICLR},
}

@inproceedings{adamw,
	title={Decoupled weight decay regularization},
	author={Loshchilov, Ilya and Hutter, Frank},
	booktitle={ICLR},
	year={2019}
}

@article{movielens,
	title={The movielens datasets: History and context},
	author={Harper, F Maxwell and Konstan, Joseph A},
	journal={ACM transactions on interactive intelligent systems (TIIS)},
	volume={5},
	number={4},
	pages={1--19},
	year={2015},
	publisher={ACM New York, NY, USA}
}

@inproceedings{squad-paper,
  author={Pranav Rajpurkar and Jian Zhang and Konstantin Lopyrev and Percy Liang},
  title={{SQuAD}: 100,000+ Questions for Machine Comprehension of Text},
  year={2016},
  booktitle={EMNLP},
}

@inproceedings{librispeech,
	title={Librispeech: an {ASR} corpus based on public domain audio books},
	author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
	booktitle={IEEE international conference on acoustics, speech and signal processing (ICASSP)},
	year={2015},
}

@article{twitter-sentiment,
	title={Twitter sentiment classification using distant supervision},
	author={Go, Alec and Bhayani, Richa and Huang, Lei},
	journal={Stanford CS224N project report},
	year={2009}
}

@article{censor1977pareto,
	title={Pareto optimality in multiobjective problems},
	author={Censor, Yair},
	journal={Applied Mathematics and Optimization},
	volume={4},
	number={1},
	pages={41--59},
	year={1977},
	publisher={Springer}
}

@inproceedings{chameleoncloud,
	title={Lessons learned from the chameleon testbed},
	author={Keahey, Kate and Anderson, Jason and Zhen, Zhuo and Riteau, Pierre and Ruth, Paul and Stanzione, Dan and Cevik, Mert and Colleran, Jacob and Gunawi, Haryadi S and Hammock, Cody and others},
	booktitle={ATC},
	year={2020}
}

@inproceedings{cloudlab,
	title={The Design and Operation of {CloudLab}},
	author={Duplyakin, Dmitry and Ricci, Robert and Maricq, Aleksander and Wong, Gary and Duerig, Jonathon and Eide, Eric and Stoller, Leigh and Hibler, Mike and Johnson, David and Webb, Kirk and others},
	booktitle={ATC},
	year={2019}
}

@inproceedings{odpp,
  title={Indicator-directed dynamic power management for iterative workloads on {GPU}-accelerated systems},
  author={Zou, Pengfei and Li, Ang and Barker, Kevin and Ge, Rong},
  booktitle={2020 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet Computing (CCGRID)},
  year={2020},
  organization={IEEE}
}

@article{gpoeo,
  title={Dynamic {GPU} Energy Optimization for Machine Learning Training Workloads},
  author={Wang, Farui and Zhang, Weizhe and Lai, Shichao and Hao, Meng and Wang, Zheng},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  year={2021},
  publisher={IEEE}
}

@inproceedings{dvfs-impact,
  title={The impact of {GPU} {DVFS} on the energy and performance of deep learning: An empirical study},
  author={Tang, Zhenheng and Wang, Yuxin and Wang, Qiang and Chu, Xiaowen},
  booktitle={Proceedings of the Tenth ACM International Conference on Future Energy Systems},
  year={2019}
}

@inproceedings{alert,
  title={{ALERT}: Accurate learning for energy and timeliness},
  author={Wan, Chengcheng and Santriaji, Muhammad and Rogers, Eri and Hoffmann, Henry and Maire, Michael and Lu, Shan},
  booktitle={ATC},
  year={2020}
}

@inproceedings{mobile-inference-energy-acc,
  title={Design considerations for energy-efficient inference on edge devices},
  author={Hanafy, Walid A and Molom-Ochir, Tergel and Shenoy, Rohan},
  booktitle={Proceedings of the Twelfth ACM International Conference on Future Energy Systems},
  pages={302--308},
  year={2021}
}


@inproceedings{edgebert,
	title        = {{EdgeBERT}: Sentence-level energy optimizations for latency-aware multi-task {NLP} inference},
	author       = {Tambe, Thierry and Hooper, Coleman and Pentecost, Lillian and Jia, Tianyu and Yang, En-Yu and Donato, Marco and Sanh, Victor and Whatmough, Paul and Rush, Alexander M and Brooks, David and others},
	year         = 2021,
	booktitle    = {MICRO}
}

@article{randomness-DNN,
  title={Randomness in neural networks: an overview},
  author={Scardapane, Simone and Wang, Dianhui},
  journal={Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  volume={7},
  number={2},
  pages={e1200},
  year={2017},
  publisher={Wiley Online Library}
}

@inproceedings{ts-regret-bound,
  title={Further optimal regret bounds for thompson sampling},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={Artificial intelligence and statistics},
  pages={99--107},
  year={2013},
  organization={PMLR}
}

@inproceedings{agrawal2012analysis,
  title={Analysis of thompson sampling for the multi-armed bandit problem},
  author={Agrawal, Shipra and Goyal, Navin},
  booktitle={Conference on learning theory},
  pages={39--1},
  year={2012},
  organization={JMLR Workshop and Conference Proceedings}
}

@inproceedings{largebatch1,
  title={On large-batch training for deep learning: Generalization gap and sharp minima},
  author={Keskar, Nitish Shirish and Mudigere, Dheevatsa and Nocedal, Jorge and Smelyanskiy, Mikhail and Tang, Ping Tak Peter},
  booktitle={ICLR},
  year={2017}
}

@article{largebatch2,
  title={On the computational inefficiency of large batch sizes for stochastic gradient descent},
  author={Golmant, Noah and Vemuri, Nikita and Yao, Zhewei and Feinberg, Vladimir and Gholami, Amir and Rothauge, Kai and Mahoney, Michael W and Gonzalez, Joseph},
  journal={arXiv preprint arXiv:1811.12941},
  year={2018}
}

@article{smallbatch,
  title={An overview of gradient descent optimization algorithms},
  author={Ruder, Sebastian},
  journal={arXiv preprint arXiv:1609.04747},
  year={2016}
}

@inproceedings{huggingface,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Wolf, Thomas  and
      Debut, Lysandre  and
      Sanh, Victor  and
      Chaumond, Julien  and
      Delangue, Clement  and
      Moi, Anthony  and
      Cistac, Pierric  and
      Rault, Tim  and
      Louf, Remi  and
      Funtowicz, Morgan  and
      Davison, Joe  and
      Shleifer, Sam  and
      von Platen, Patrick  and
      Ma, Clara  and
      Jernite, Yacine  and
      Plu, Julien  and
      Xu, Canwen  and
      Le Scao, Teven  and
      Gugger, Sylvain  and
      Drame, Mariama  and
      Lhoest, Quentin  and
      Rush, Alexander",
    booktitle = "EMNLP",
    year = "2020",
}

@inproceedings{network-calculus,
  title={A calculus for network delay, Part I: Network elements in isolation},
  author={Rene L. Cruz},
  booktitle={IEEE/ACM Transactions on Information Theory},
  year={1991},
}

@article{gpu-nest,
  title={{GPU}-nest: Characterizing energy efficiency of multi-{GPU} inference servers},
  author={Jahanshahi, Ali and Sabzi, Hadi Zamani and Lau, Chester and Wong, Daniel},
  journal={IEEE Computer Architecture Letters},
  volume={19},
  number={2},
  pages={139--142},
  year={2020},
  publisher={IEEE}
}

@article{energy-clusterman,
  title={Cost Efficient {GPU} Cluster Management for Training and Inference of Deep Learning},
  author={Kang, Dong-Ki and Lee, Ki-Beom and Kim, Young-Chon},
  journal={Energies},
  volume={15},
  number={2},
  pages={474},
  year={2022},
  publisher={Multidisciplinary Digital Publishing Institute}
}

@article{case-for-energy-proportional,
  title={The case for energy-proportional computing},
  author={Barroso, Luiz Andr{\'e} and H{\"o}lzle, Urs},
  journal={Computer},
  volume={40},
  number={12},
  pages={33--37},
  year={2007},
  publisher={IEEE}
}

@inproceedings{gradmatch-icml,
	title        = {Grad-match: Gradient matching based data subset selection for efficient deep model training},
	author       = {Killamsetty, Krishnateja and Durga, S and Ramakrishnan, Ganesh and De, Abir and Iyer, Rishabh},
	year         = 2021,
	booktitle    = {ICML}
}

@article{energy-nlp-policy,
  title={Energy and policy considerations for deep learning in {NLP}},
  author={Strubell, Emma and Ganesh, Ananya and McCallum, Andrew},
  journal={Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics},
  year={2019}
}

@article{quantify-carbon,
  title={Quantifying the carbon emissions of machine learning},
  author={Lacoste, Alexandre and Luccioni, Alexandra and Schmidt, Victor and Dandres, Thomas},
  journal={arXiv preprint arXiv:1910.09700},
  year={2019}
}

@article{google-tpu,
  title={A domain-specific architecture for deep neural networks},
  author={Jouppi, Norman P and Young, Cliff and Patil, Nishant and Patterson, David},
  journal={Communications of the ACM},
  volume={61},
  number={9},
  pages={50--59},
  year={2018},
  publisher={ACM New York, NY, USA}
}

@misc{us-household,
	title        = {{{How much electricity does an American home use?}}},
	howpublished = {\url{https://www.eia.gov/tools/faqs/faq.php?id=97&t=3}}
}

@inproceedings{build-ontopof-impact-tracker,
    title = "Towards Accurate and Reliable Energy Measurement of {NLP} Models",
    author = "Cao, Qingqing  and
      Balasubramanian, Aruna  and
      Balasubramanian, Niranjan",
    booktitle = "Proceedings of SustaiNLP: Workshop on Simple and Efficient Natural Language Processing",
    year = "2020",
}

@inproceedings {ansor,
author = {Lianmin Zheng and Chengfan Jia and Minmin Sun and Zhao Wu and Cody Hao Yu and Ameer Haj-Ali and Yida Wang and Jun Yang and Danyang Zhuo and Koushik Sen and Joseph E. Gonzalez and Ion Stoica},
title = {Ansor: Generating High-Performance Tensor Programs for Deep Learning},
booktitle = {OSDI},
year = {2020}
}

@inproceedings{taso,
	title        = {{TASO}: Optimizing Deep Learning Computation with Automatic Generation of Graph Substitutions},
	author       = {Jia, Zhihao and Padon, Oded and Thomas, James and Warszawski, Todd and Zaharia, Matei and Aiken, Alex},
	year         = 2019,
	booktitle    = {SOSP},
}
@inproceedings{PET,
	title        = {{PET}: Optimizing Tensor Programs with Partially Equivalent Transformations and Automated Corrections},
	author       = {Haojie Wang and Jidong Zhai and Mingyu Gao and Zixuan Ma and Shizhi Tang and Liyan Zheng and Yuanzhi Li and Kaiyuan Rong and Yuanyong Chen and Zhihao Jia},
	year         = 2021,
	booktitle    = {OSDI}
}

@article{gpu-power-survey,
  title={Understanding GPU power: A survey of profiling, modeling, and simulation methods},
  author={Bridges, Robert A and Imam, Neena and Mintz, Tiffany M},
  journal={ACM Computing Surveys (CSUR)},
  volume={49},
  number={3},
  pages={1--27},
  year={2016},
  publisher={ACM New York, NY, USA}
}

@article{estimation-energy-ml,
  title={Estimation of energy consumption in machine learning},
  author={Garc{\'\i}a-Mart{\'\i}n, Eva and Rodrigues, Crefeda Faviola and Riley, Graham and Grahn, H{\aa}kan},
  journal={Journal of Parallel and Distributed Computing},
  volume={134},
  pages={75--88},
  year={2019},
  publisher={Elsevier}
}

@inproceedings{dvfs-taskmap-powercap,
  title={Power capping of {CPU}-{GPU} heterogeneous systems through coordinating {DVFS} and task mapping},
  author={Komoda, Toshiya and Hayashi, Shingo and Nakada, Takashi and Miwa, Shinobu and Nakamura, Hiroshi},
  booktitle={2013 IEEE 31st International Conference on computer design (ICCD)},
  year={2013},
  organization={IEEE}
}


@inproceedings{gpu-energy-adaptive-data-compression,
  title={Exploiting adaptive data compression to improve performance and energy-efficiency of compute workloads in multi-GPU systems},
  author={Tavana, Mohammad Khavari and Sun, Yifan and Agostini, Nicolas Bohm and Kaeli, David},
  booktitle={2019 IEEE International Parallel and Distributed Processing Symposium (IPDPS)},
  pages={664--674},
  year={2019},
  organization={IEEE}
}

@inproceedings{dynamic-underclock-gpu,
  title={DUB: Dynamic underclocking and bypassing in {NoCs} for heterogeneous {GPU} workloads},
  author={Bharadwaj, Srikant and Das, Shomit and Eckert, Yasuko and Oskin, Mark and Krishna, Tushar},
  booktitle={2021 15th IEEE/ACM International Symposium on Networks-on-Chip (NOCS)},
  year={2021},
}

@inproceedings{batchsizer,
  title={BatchSizer: Power-performance tradeoff for {DNN} inference},
  author={Nabavinejad, Seyed Morteza and Reda, Sherief and Ebrahimi, Masoumeh},
  booktitle={Proceedings of the 26th Asia and South Pacific Design Automation Conference},
  year={2021}
}

@inproceedings{gpgpu-power-estimate,
  title={GPGPU performance and power estimation using machine learning},
  author={Wu, Gene and Greathouse, Joseph L and Lyashevsky, Alexander and Jayasena, Nuwan and Chiou, Derek},
  booktitle={2015 IEEE 21st international symposium on high performance computer architecture (HPCA)},
  pages={564--576},
  year={2015},
  organization={IEEE}
}

@article{gpgpu-model-dvfs,
  title={GPGPU performance estimation with core and memory frequency scaling},
  author={Wang, Qiang and Chu, Xiaowen},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={31},
  number={12},
  pages={2865--2881},
  year={2020},
  publisher={IEEE}
}

@article{warmstart-training,
	title        = {On warm-starting neural network training},
	author       = {Ash, Jordan and Adams, Ryan P},
	year         = 2020,
	journal      = {NeurIPS}
}

@inproceedings{verified-gpu-instruction-energy-model,
  title={Verified instruction-level energy consumption measurement for {NVIDIA} {GPUs}},
  author={Arafa, Yehia and ElWazir, Ammar and ElKanishy, Abdelrahman and Aly, Youssef and Elsayed, Ayatelrahman and Badawy, Abdel-Hameed and Chennupati, Gopinath and Eidenbenz, Stephan and Santhi, Nandakishore},
  booktitle={Proceedings of the 17th ACM International Conference on Computing Frontiers},
  year={2020}
}

@inproceedings{accelwattch,
  title={{AccelWattch}: A Power Modeling Framework for Modern {GPUs}},
  author={Kandiah, Vijay and Peverelle, Scott and Khairy, Mahmoud and Pan, Junrui and Manjunath, Amogh and Rogers, Timothy G and Aamodt, Tor M and Hardavellas, Nikos},
  booktitle={MICRO},
  year={2021}
}

@inproceedings{pollux,
	title        = {Pollux: Co-adaptive cluster scheduling for goodput-optimized deep learning},
	author       = {Qiao, Aurick and Choe, Sang Keun and Subramanya, Suhas Jayaram and Neiswanger, Willie and Ho, Qirong and Zhang, Hao and Ganger, Gregory R and Xing, Eric P},
	year         = 2021,
	booktitle    = {OSDI}
}

@inproceedings{pipedream,
	title        = {PipeDream: generalized pipeline parallelism for {DNN} training},
	author       = {Narayanan, Deepak and Harlap, Aaron and Phanishayee, Amar and Seshadri, Vivek and Devanur, Nikhil R and Ganger, Gregory R and Gibbons, Phillip B and Zaharia, Matei},
	year         = 2019,
	booktitle    = {SOSP}
}

@inproceedings{zero,
  author={Rajbhandari, Samyam and Rasley, Jeff and Ruwase, Olatunji and He, Yuxiong},
  booktitle={International Conference for High Performance Computing, Networking, Storage and Analysis (SC)}, 
  title={{ZeRO}: Memory optimizations Toward Training Trillion Parameter Models}, 
  year={2020},
}

@article{gspmd,
  title={{GSPMD}: general and scalable parallelization for {ML} computation graphs},
  author={Xu, Yuanzhong and Lee, HyoukJoong and Chen, Dehao and Hechtman, Blake and Huang, Yanping and Joshi, Rahul and Krikun, Maxim and Lepikhin, Dmitry and Ly, Andy and Maggioni, Marcello and others},
  journal={arXiv preprint arXiv:2105.04663},
  year={2021}
}

@inproceedings{oort,
	title        = {Oort: Efficient federated learning via guided participant selection},
	author       = {Lai, Fan and Zhu, Xiangfeng and Madhyastha, Harsha V and Chowdhury, Mosharaf},
	year         = 2021,
	booktitle    = {OSDI}
}

@inproceedings{bytescheduler,
	title        = {A generic communication scheduler for distributed {DNN} training acceleration},
	author       = {Peng, Yanghua and Zhu, Yibo and Chen, Yangrui and Bao, Yixin and Yi, Bairen and Lan, Chang and Wu, Chuan and Guo, Chuanxiong},
	year         = 2019,
	booktitle    = {SOSP}
}

@inproceedings{blinkml,
	author = {Wang, Guanhua and Venkataraman, Shivaram and Phanishayee, Amar and Devanur, Nikhil and Thelin, Jorgen and Stoica, Ion},
	booktitle = {Proceedings of Machine Learning and Systems},
	title = {Blink: Fast and Generic Collectives for Distributed {ML}},
	year = {2020}
}

@article{gns,
  title={An empirical model of large-batch training},
  author={McCandlish, Sam and Kaplan, Jared and Amodei, Dario and Team, OpenAI Dota},
  journal={arXiv preprint arXiv:1812.06162},
  year={2018}
}

@article{kmeans,
  title={Algorithm AS 136: A k-means clustering algorithm},
  author={Hartigan, John A and Wong, Manchek A},
  journal={Journal of the royal statistical society. series c (applied statistics)},
  volume={28},
  number={1},
  pages={100--108},
  year={1979},
  publisher={JSTOR}
}

@article{imagenet1hour,
  title={Accurate, large minibatch {SGD}: Training {ImageNet} in 1 hour},
  author={Goyal, Priya and Doll{\'a}r, Piotr and Girshick, Ross and Noordhuis, Pieter and Wesolowski, Lukasz and Kyrola, Aapo and Tulloch, Andrew and Jia, Yangqing and He, Kaiming},
  journal={arXiv preprint arXiv:1706.02677},
  year={2017}
}

@inproceedings{incbs,
  title={Don't decay the learning rate, increase the batch size},
  author={Smith, Samuel L and Kindermans, Pieter-Jan and Ying, Chris and Le, Quoc V},
  booktitle={ICLR},
  year={2018}
}

@book{goodfellowdl,
  title={Deep learning},
  author={Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
  year={2016},
  publisher={MIT press}
}

@article{fluid,
  title={Fluid: Resource-aware Hyperparameter Tuning Engine},
  author={Yu, Peifeng and Liu, Jiachen and Chowdhury, Mosharaf},
  journal={MLSys},
  year={2021}
}

@article{hpo,
  title={Algorithms for hyper-parameter optimization},
  author={Bergstra, James and Bardenet, R{\'e}mi and Bengio, Yoshua and K{\'e}gl, Bal{\'a}zs},
  journal={NeurIPS},
  year={2011}
}

@article{asha,
  title={A system for massively parallel hyperparameter tuning},
  author={Li, Liam and Jamieson, Kevin and Rostamizadeh, Afshin and Gonina, Ekaterina and Ben-Tzur, Jonathan and Hardt, Moritz and Recht, Benjamin and Talwalkar, Ameet},
  journal={Proceedings of Machine Learning and Systems},
  volume={2},
  pages={230--246},
  year={2020}
}

@article{hyperband,
  title={Hyperband: A novel bandit-based approach to hyperparameter optimization},
  author={Li, Lisha and Jamieson, Kevin and DeSalvo, Giulia and Rostamizadeh, Afshin and Talwalkar, Ameet},
  journal={The Journal of Machine Learning Research},
  volume={18},
  number={1},
  pages={6765--6816},
  year={2017},
  publisher={JMLR. org}
}
